{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRi_BXPfJiV7"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# üß† CAMPUS CONNECT: SECURE CLOUD AI SERVER\n",
        "# ==========================================\n",
        "\n",
        "# 1. Install Dependencies\n",
        "!pip install fastapi uvicorn pyngrok python-multipart transformers torch pillow nest_asyncio\n",
        "\n",
        "import uvicorn\n",
        "import getpass\n",
        "import os\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from pyngrok import ngrok\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "import io\n",
        "import nest_asyncio\n",
        "\n",
        "# 2. Load the BLIP Model (Downloads to Colab GPU)\n",
        "print(\"‚è≥ Loading BLIP Model... (This takes ~30s)\")\n",
        "captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\", device=0)\n",
        "print(\"‚úÖ BLIP Model Loaded & Ready!\")\n",
        "\n",
        "# 3. Define the API\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/analyze\")\n",
        "async def analyze(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        # Read the uploaded image\n",
        "        image_data = await file.read()\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "        # Run Inference\n",
        "        result = captioner(image, max_new_tokens=20)\n",
        "        text = result[0]['generated_text']\n",
        "\n",
        "        return {\"description\": text}\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# 4. SECURE TOKEN INPUT\n",
        "print(\"üëá Paste your Ngrok Authtoken in the box below and hit Enter:\")\n",
        "NGROK_AUTH_TOKEN = getpass.getpass()\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# 5. Open the Tunnel\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "\n",
        "print(\"=\"*60)\n",
        "# This is the URL you need to copy to your laptop\n",
        "print(f\"üöÄ YOUR PUBLIC URL IS:  {public_url}/analyze\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 6. Start the Server (FIXED FOR COLAB)\n",
        "# We use 'await' here to respect the notebook's environment\n",
        "config = uvicorn.Config(app, port=8000)\n",
        "server = uvicorn.Server(config)\n",
        "await server.serve()"
      ]
    }
  ]
}